---
layout: post,
title: Gaussian Splatting 测试+代码解读
date: 2024-04-10 20:51
category: Category
author: User
tags: [3dgs]
summary: Summary of the article
---

# gaussian splatting代码测试+解读

测试输入:

    训练图像194
    初始点云5.4k 
测试结果(粗略的计时, 因为这其中包含了加载和保存文件的时间):
    
    7k-iter 5min
    30k-iter 30min

测试训练结果

~~~bash 
./SIBR_viewers/install/bin/SIBR_gaussianViewer_app -m /home/lab/gs/output/bicycle/ -path /home/lab/gs/360_v2/bicycle
~~~

~~~bash
(gs) lab@lab-PC:~/workspace/cxx/gaussian-splatting$ python train.py -s /home/lab/gs/360_v2/bicycle -m /home/lab/gs/output/bicycle
Optimizing /home/lab/gs/output/bicycle
Output folder: /home/lab/gs/output/bicycle [06/12 19:00:54]
Tensorboard not available: not logging progress [06/12 19:00:54]
Reading camera 194/194 [06/12 19:00:54]
Converting point3d.bin to .ply, will happen only the first time you open the scene. [06/12 19:00:54]
Loading Training Cameras [06/12 19:00:54]
[ INFO ] Encountered quite large input images (>1.6K pixels width), rescaling to 1.6K.
 If this is not desired, please explicitly specify '--resolution/-r' as 1 [06/12 19:00:54]
Loading Test Cameras [06/12 19:01:55]
Number of points at initialisation :  54275 [06/12 19:01:55]
Training progress:  23%|██████████████████████████████████████████████▏                                                                                                                                                       | 7000/30000 [03:52<18:27, 20.76it/s, Loss=0.0939351]
[ITER 7000] Evaluating train: L1 0.03885948732495308 PSNR 23.782460403442386 [06/12 19:05:48]

[ITER 7000] Saving Gaussians [06/12 19:05:48]
Training progress: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 30000/30000 [30:02<00:00, 16.65it/s, Loss=0.0589145]

[ITER 30000] Evaluating train: L1 0.026784038916230202 PSNR 27.015393829345705 [06/12 19:31:58]

[ITER 30000] Saving Gaussians [06/12 19:31:58]

Training complete. [06/12 19:32:19]
~~~

/scene/colmap_loader.cpp 中有函数write_points3D_binary用于将一组三维点云(point3D)写入.bin文件中

~~~bash
def write_points3D_binary(points3D, path_to_model_file):
    """
    see: src/colmap/scene/reconstruction.cc
        void Reconstruction::ReadPoints3DBinary(const std::string& path)
        void Reconstruction::WritePoints3DBinary(const std::string& path)
    """
    with open(path_to_model_file, "wb") as fid:
        write_next_bytes(fid, len(points3D), "Q")
        for _, pt in points3D.items():
            write_next_bytes(fid, pt.id, "Q")
            write_next_bytes(fid, pt.xyz.tolist(), "ddd")
            write_next_bytes(fid, pt.rgb.tolist(), "BBB")
            write_next_bytes(fid, pt.error, "d")
            track_length = pt.image_ids.shape[0]
            write_next_bytes(fid, track_length, "Q")
            for image_id, point2D_id in zip(pt.image_ids, pt.point2D_idxs):
                write_next_bytes(fid, [image_id, point2D_id], "ii")， 
~~~

另一个函数用来读取bin文件：

~~~bash
def read_points3D_binary(path_to_model_file):
    """
    see: src/base/reconstruction.cc
        void Reconstruction::ReadPoints3DBinary(const std::string& path)
        void Reconstruction::WritePoints3DBinary(const std::string& path)
    """


    with open(path_to_model_file, "rb") as fid:
        num_points = read_next_bytes(fid, 8, "Q")[0]

        xyzs = np.empty((num_points, 3))
        rgbs = np.empty((num_points, 3))
        errors = np.empty((num_points, 1))

        for p_id in range(num_points):
            binary_point_line_properties = read_next_bytes(
                fid, num_bytes=43, format_char_sequence="QdddBBBd")
            xyz = np.array(binary_point_line_properties[1:4])
            rgb = np.array(binary_point_line_properties[4:7])
            error = np.array(binary_point_line_properties[7])
            track_length = read_next_bytes(
                fid, num_bytes=8, format_char_sequence="Q")[0]  # "image_ids", 
            track_elems = read_next_bytes(
                fid, num_bytes=8*track_length,
                format_char_sequence="ii"*track_length)  # "point2D_idxs"
            xyzs[p_id] = xyz
            rgbs[p_id] = rgb
            errors[p_id] = error
    return xyzs, rgbs, errors 
~~~

观察这两个函数可以发现，在读取.bin文件后,仅使用了其中的***xyz***,***rgb***,***error***这三个属性。所以如果使用已有的三维点云来替换colmap的生成结果, 该点云需要包含下列属性：
    
    - (n,3)的点云坐标xyz，
    - (n,3)的颜色rgbs，
    - (n,1)的errors，其中errors的值全部为0. 
创建一组points3D，填充其属性，使其可以使用write_points3D_binary写入为一个bin文件，同时还能够被read_points3D_binary读取。

参考 [Colmap Doc: Output Format](https://colmap.github.io/format.html)

colmap输出的文件可以保存为二进制文件(.bin)也可以保存为文本文件(.txt), 唯一区别只有是否方便人类阅读。
  
> \# 3D point list with one line of data per point:
\# POINT3D_ID, X, Y, Z, R, G, B, ERROR, TRACK[] as (IMAGE_ID, POINT2D_IDX)
\# Number of points: 3, mean track length: 3.3334
63390 1.67241 0.292931 0.609726 115 121 122 **1.33927** 16 6542 15 7345 6 6714 14 7227
63376 2.01848 0.108877 -0.0260841 102 209 250 **1.73449** 16 6519 15 7322 14 7212 8 3991
63371 1.71102 0.28566 0.53475 245 251 249 **0.612829** 118 4140 117 4473

其中的errors是重投影误差，是估计的3D点投影到图像之后的位置与实际观测的位置之间欧氏距离（是小数是因为3D点投影到2D图像后大概率得到的是一个浮点数坐标）。如果3D点是深度图像反投影得到的，同时深度图和彩色图像已经完成了对齐，那么理论上errors应该为0.

# parameter

    lp = ModelParams(parser)  # 模型参数（源数据）
    op = OptimizationParams(parser)  # 优化参数（包含学习率等）
    pp = PipelineParams(parser)

其中ModelParams主要包含

PipelineParams中convert_SHs_python和compute_cov3D_python是在init时控制谐波颜色与三维协方差的预计算



~~~
class PipelineParams(ParamGroup):
    def __init__(self, parser):
        self.convert_SHs_python = False
        self.compute_cov3D_python = False
        self.debug = False
        super().__init__(parser, "Pipeline Parameters")
~~~

如果提供了预计算的颜色(override_color)，使用它们。否则，如果希望在Python中从SH中预计算颜色#，请执行此操作。如果不执行此操作，则SH->RGB转换将由光栅化器完成。
~~~
# If precomputed colors are provided, use them. Otherwise, if it is desired to precompute colors
# from SHs in Python, do it. If not, then SH -> RGB conversion will be done by rasterizer.
shs = None
colors_precomp = None
if override_color is None:
    if pipe.convert_SHs_python:
        shs_view = pc.get_features.transpose(1, 2).view(-1, 3, (pc.max_sh_degree+1)**2)
        dir_pp = (pc.get_xyz - viewpoint_camera.camera_center.repeat(pc.get_features.shape[0], 1))
        dir_pp_normalized = dir_pp/dir_pp.norm(dim=1, keepdim=True)
        sh2rgb = eval_sh(pc.active_sh_degree, shs_view, dir_pp_normalized)
        colors_precomp = torch.clamp_min(sh2rgb + 0.5, 0.0)
    else:
        shs = pc.get_features
~~~

#如果提供了预先计算的三维协方差，请使用它。如果没有，则光栅化器将根据#缩放/旋转来计算它。
~~~
if pipe.compute_cov3D_python:
    cov3D_precomp = pc.get_covariance(scaling_modifier)
~~~

