---
title: Gaussian Splatting 测试+代码解读
date: 2024-04-10 20:51
category: 3D Gaussian Splatting
author: User
tags: [gaussian splatting]
summary: Summary of the article
math: true
---
## 小场景测试结果

测试输入:

    图像194帧(640, 480), colmap生成的初始点云点的数量:5.4k

测试结果(粗略的计时, 因为这其中包含了加载和保存文件的时间):
    
    7k-iter 5min
    30k-iter 30min

测试训练结果

~~~bash 
./SIBR_viewers/install/bin/SIBR_gaussianViewer_app -m /home/lab/gs/output/bicycle/ -path /home/lab/gs/360_v2/bicycle
~~~

~~~bash
(gs) lab@lab-PC:~/workspace/cxx/gaussian-splatting$ python train.py -s /home/lab/gs/360_v2/bicycle -m /home/lab/gs/output/bicycle
Optimizing /home/lab/gs/output/bicycle
Output folder: /home/lab/gs/output/bicycle [06/12 19:00:54]
Tensorboard not available: not logging progress [06/12 19:00:54]
Reading camera 194/194 [06/12 19:00:54]
Converting point3d.bin to .ply, will happen only the first time you open the scene. [06/12 19:00:54]
Loading Training Cameras [06/12 19:00:54]
[ INFO ] Encountered quite large input images (>1.6K pixels width), rescaling to 1.6K.
 If this is not desired, please explicitly specify '--resolution/-r' as 1 [06/12 19:00:54]
Loading Test Cameras [06/12 19:01:55]
Number of points at initialisation :  54275 [06/12 19:01:55]
Training progress:  23%|██████████████████████████████████████████████▏                                                                                                                                                       | 7000/30000 [03:52<18:27, 20.76it/s, Loss=0.0939351]
[ITER 7000] Evaluating train: L1 0.03885948732495308 PSNR 23.782460403442386 [06/12 19:05:48]

[ITER 7000] Saving Gaussians [06/12 19:05:48]
Training progress: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 30000/30000 [30:02<00:00, 16.65it/s, Loss=0.0589145]

[ITER 30000] Evaluating train: L1 0.026784038916230202 PSNR 27.015393829345705 [06/12 19:31:58]

[ITER 30000] Saving Gaussians [06/12 19:31:58]

Training complete. [06/12 19:32:19]
~~~

/scene/colmap_loader.cpp 中有函数write_points3D_binary用于将一组三维点云(point3D)写入.bin文件中

~~~bash
def write_points3D_binary(points3D, path_to_model_file):
    """
    see: src/colmap/scene/reconstruction.cc
        void Reconstruction::ReadPoints3DBinary(const std::string& path)
        void Reconstruction::WritePoints3DBinary(const std::string& path)
    """
    with open(path_to_model_file, "wb") as fid:
        write_next_bytes(fid, len(points3D), "Q")
        for _, pt in points3D.items():
            write_next_bytes(fid, pt.id, "Q")
            write_next_bytes(fid, pt.xyz.tolist(), "ddd")
            write_next_bytes(fid, pt.rgb.tolist(), "BBB")
            write_next_bytes(fid, pt.error, "d")
            track_length = pt.image_ids.shape[0]
            write_next_bytes(fid, track_length, "Q")
            for image_id, point2D_id in zip(pt.image_ids, pt.point2D_idxs):
                write_next_bytes(fid, [image_id, point2D_id], "ii")， 
~~~

另一个函数用来读取bin文件：

~~~bash
def read_points3D_binary(path_to_model_file):
    """
    see: src/base/reconstruction.cc
        void Reconstruction::ReadPoints3DBinary(const std::string& path)
        void Reconstruction::WritePoints3DBinary(const std::string& path)
    """


    with open(path_to_model_file, "rb") as fid:
        num_points = read_next_bytes(fid, 8, "Q")[0]

        xyzs = np.empty((num_points, 3))
        rgbs = np.empty((num_points, 3))
        errors = np.empty((num_points, 1))

        for p_id in range(num_points):
            binary_point_line_properties = read_next_bytes(
                fid, num_bytes=43, format_char_sequence="QdddBBBd")
            xyz = np.array(binary_point_line_properties[1:4])
            rgb = np.array(binary_point_line_properties[4:7])
            error = np.array(binary_point_line_properties[7])
            track_length = read_next_bytes(
                fid, num_bytes=8, format_char_sequence="Q")[0]  # "image_ids", 
            track_elems = read_next_bytes(
                fid, num_bytes=8*track_length,
                format_char_sequence="ii"*track_length)  # "point2D_idxs"
            xyzs[p_id] = xyz
            rgbs[p_id] = rgb
            errors[p_id] = error
    return xyzs, rgbs, errors 
~~~

观察这两个函数可以发现，在读取.bin文件后,仅使用了其中的***xyz***,***rgb***,***error***这三个属性。所以如果使用已有的三维点云来替换colmap的生成结果, 该点云需要包含下列属性：
    
    - (n,3)的点云坐标xyz，
    - (n,3)的颜色rgbs，
    - (n,1)的errors，其中errors的值全部为0. 
创建一组points3D，填充其属性，使其可以使用write_points3D_binary写入为一个bin文件，同时还能够被read_points3D_binary读取。

参考 [Colmap Doc: Output Format](https://colmap.github.io/format.html)

colmap输出的文件可以保存为二进制文件(.bin)也可以保存为文本文件(.txt), 唯一区别只有是否方便人类阅读。
  
> \# 3D point list with one line of data per point:
\# POINT3D_ID, X, Y, Z, R, G, B, ERROR, TRACK[] as (IMAGE_ID, POINT2D_IDX)
\# Number of points: 3, mean track length: 3.3334
63390 1.67241 0.292931 0.609726 115 121 122 **1.33927** 16 6542 15 7345 6 6714 14 7227
63376 2.01848 0.108877 -0.0260841 102 209 250 **1.73449** 16 6519 15 7322 14 7212 8 3991
63371 1.71102 0.28566 0.53475 245 251 249 **0.612829** 118 4140 117 4473

其中的errors是重投影误差，是估计的3D点投影到图像之后的位置与实际观测的位置之间欧氏距离（是小数是因为3D点投影到2D图像后大概率得到的是一个浮点数坐标）。如果3D点是深度图像反投影得到的，同时深度图和彩色图像已经完成了对齐，那么理论上errors应该为0.


## train 分析
### parameter

    lp = ModelParams(parser)  # 模型参数（源数据）
    op = OptimizationParams(parser)  # 优化参数（包含学习率等）
    pp = PipelineParams(parser)

其中ModelParams主要包含

PipelineParams中convert_SHs_python和compute_cov3D_python是在init时控制谐波颜色与三维协方差的预计算



~~~
class PipelineParams(ParamGroup):
    def __init__(self, parser):
        self.convert_SHs_python = False
        self.compute_cov3D_python = False
        self.debug = False
        super().__init__(parser, "Pipeline Parameters")
~~~

如果提供了预计算的颜色(override_color)，使用它们。否则，如果希望在Python中从SH中预计算颜色#，请执行此操作。如果不执行此操作，则SH->RGB转换将由光栅化器完成。
~~~
# If precomputed colors are provided, use them. Otherwise, if it is desired to precompute colors
# from SHs in Python, do it. If not, then SH -> RGB conversion will be done by rasterizer.
shs = None
colors_precomp = None
if override_color is None:
    if pipe.convert_SHs_python:
        shs_view = pc.get_features.transpose(1, 2).view(-1, 3, (pc.max_sh_degree+1)**2)
        dir_pp = (pc.get_xyz - viewpoint_camera.camera_center.repeat(pc.get_features.shape[0], 1))
        dir_pp_normalized = dir_pp/dir_pp.norm(dim=1, keepdim=True)
        sh2rgb = eval_sh(pc.active_sh_degree, shs_view, dir_pp_normalized)
        colors_precomp = torch.clamp_min(sh2rgb + 0.5, 0.0)
    else:
        shs = pc.get_features
~~~

#如果提供了预先计算的三维协方差，请使用它。如果没有，则光栅化器将根据#缩放/旋转来计算它。
~~~
if pipe.compute_cov3D_python:
    cov3D_precomp = pc.get_covariance(scaling_modifier)
~~~

## training flow

~~~
def training(dataset, opt, pipe, testing_iterations, saving_iterations, checkpoint_iterations, checkpoint, debug_from):
~~~
与输入的参数对应
~~~
training(lp.extract(args), op.extract(args), pp.extract(args), args.test_iterations, args.save_iterations, args.checkpoint_iterations, args.start_checkpoint, args.debug_from)
~~~
我们可以拿到对应关系

    dataset                 - lp.extract(args)
    opt                     - op.extract(args)
    pipe                    - pp.extract(args)
    testing_iterations      - args.test_iterations
    saving_iterations       - args.save_iterations
    checkpoint_iterations   - args.checkpoint_iterations
    checkpoint              - args.start_checkpoint
    debug_from              - args.debug_from

首先来到dataset参数, 其用于各种初始化，lp来自
~~~
lp = ModelParams(parser)  # 模型参数（源数据）
~~~
其中保存了模型的源数据, 其中存储了3dgs模型的图像路径、模型路径、解析度
~~~
class ModelParams(ParamGroup): 
    def __init__(self, parser, sentinel=False):
        self.sh_degree = 3
        self._source_path = ""
        self._model_path = ""
        self._images = "images"
        self._resolution = -1
        self._white_background = False
        self.data_device = "cuda"
        self.eval = False
        super().__init__(parser, "Loading Parameters", sentinel)
~~~

比较重要的一点是dataset的sh_degree属性初始化了*GaussianModel*的*max_sh_degree*
~~~
gaussians = GaussianModel(dataset.sh_degree)
~~~


## 读取数据

以colmap格式的为例, 从images.bin读取每一帧图像对应的相机外参, 也就是相机的位姿。从camera.bin读取相机的内参。

~~~
def readColmapSceneInfo(path, images, eval, llffhold=8):
    try:
        cameras_extrinsic_file = os.path.join(path, "sparse/0", "images.bin")
        cameras_intrinsic_file = os.path.join(path, "sparse/0", "cameras.bin")
        cam_extrinsics = read_extrinsics_binary(cameras_extrinsic_file)
        cam_intrinsics = read_intrinsics_binary(cameras_intrinsic_file)
    except:
        cameras_extrinsic_file = os.path.join(path, "sparse/0", "images.txt")
        cameras_intrinsic_file = os.path.join(path, "sparse/0", "cameras.txt")
        cam_extrinsics = read_extrinsics_text(cameras_extrinsic_file)
        cam_intrinsics = read_intrinsics_text(cameras_intrinsic_file)
~~~

cam_extrinsics为dict, keys为图像的序号, 从1开始计数。value部分是scene.colmap_loader.Image, 其包含多个属性

    scene.colmap_loader.Image
        -id:                         # 图像id
        -qvec:                       # 相机外参旋转的四元数
        -tvec:                       # 相机外参位移向量
        -camera_id
        -xys:                        # (n_i, 2)
        -point3D_ids:                # (n_i, )

xys应该是3D点投影到2D平面上的2D坐标。
point3D_ids应该是与pointcloud文件中点云点的对应关系, 即对应3D点的下标。如果是-1，说明该3D点在该图像中不可见。

### readColmapCameras

该函数输出cam_infos, 

使用enumerate将从0开始的序号与图像顺序组织, 根据变量名称可以发现：images.bin存储的是相机的外参，cameras.bin存储的是内参。
~~~

def readColmapSceneInfo(path, images, eval, llffhold=8):
    try:
        cameras_extrinsic_file = os.path.join(path, "sparse/0", "images.bin")
        cameras_intrinsic_file = os.path.join(path, "sparse/0", "cameras.bin")
        cam_extrinsics = read_extrinsics_binary(cameras_extrinsic_file)
        cam_intrinsics = read_intrinsics_binary(cameras_intrinsic_file)
    except:
        cameras_extrinsic_file = os.path.join(path, "sparse/0", "images.txt")
        cameras_intrinsic_file = os.path.join(path, "sparse/0", "cameras.txt")
        cam_extrinsics = read_extrinsics_text(cameras_extrinsic_file)
        cam_intrinsics = read_intrinsics_text(cameras_intrinsic_file)

    reading_dir = "images" if images == None else images
    cam_infos_unsorted = readColmapCameras(cam_extrinsics=cam_extrinsics, cam_intrinsics=cam_intrinsics, images_folder=os.path.join(path, reading_dir))
    cam_infos = sorted(cam_infos_unsorted.copy(), key = lambda x : x.image_name)

    if eval:
        train_cam_infos = [c for idx, c in enumerate(cam_infos) if idx % llffhold != 0]
        test_cam_infos = [c for idx, c in enumerate(cam_infos) if idx % llffhold == 0]
    else:
        train_cam_infos = cam_infos
        test_cam_infos = []

    nerf_normalization = getNerfppNorm(train_cam_infos)

    ply_path = os.path.join(path, "sparse/0/points3D.ply")
    bin_path = os.path.join(path, "sparse/0/points3D.bin")
    txt_path = os.path.join(path, "sparse/0/points3D.txt")
    if not os.path.exists(ply_path):
        print("Converting point3d.bin to .ply, will happen only the first time you open the scene.")
        try:
            xyz, rgb, _ = read_points3D_binary(bin_path)
        except:
            xyz, rgb, _ = read_points3D_text(txt_path)
        storePly(ply_path, xyz, rgb)
    try:
        pcd = fetchPly(ply_path)  # 此处可以直接替换pcd, 只需要提供np.array的3个: positions(n,3) 'float32', colors(n, 3) 'float64' 0~1, normals(n,3) 'float32' 0,0,0, BasicPointCloud(points=positions, colors=colors, normals=normals)
    except:
        pcd = None

    scene_info = SceneInfo(point_cloud=pcd,  # 点云: xyzs, colors, normals
                           train_cameras=train_cam_infos,  # cam_info
                           test_cameras=test_cam_infos,  # []
                           nerf_normalization=nerf_normalization,  # translate(centuralize), radius(max dist*1.1)
                           ply_path=ply_path)  # path
    return scene_info
~~~
主要聚焦在相机外参部分, 

## 手动生成
使用read_extrinsics_binary和read_intrinsics_binary读取到的cameras_extrinsic_file与cameras_intrinsic_file都是dict, 其长度一样, key数量一致且相同。

### cameras.bin
dict中的每一项都为一个**scene.colmap_loader.Camera**的实例, 可以直接复制到和图像数量一致。
~~~
Camera(id=1, model='PINHOLE', width=640, height=480, params=array([393.465, 393.902, 320.462, 247.125]))
~~~
![cameras_intrinsic_file](/assets/img/2024-04-22-11-09-59.png)
### images.bin
相机的外部参数, dict中每一项为**scene.colmap_loader.Image**

~~~
Image
    -id: 1
    -name: '00000.png'
    -qvec: numpy.ndarray, (4,)
    -tvec: numpy.ndarray, (3,)
    -xys: numpy.ndarray, (n, 2)
    -point3D_ids: numpy.ndarray, (n,)
~~~
![cameras_extrinsic_file](/assets/img/2024-04-22-11-15-26.png)
~~~
Image(id=1, qvec=array([ 0.45617498, -0.02043279,  0.73813251,  0.49663597]), tvec=array([ 0.2200328 , -2.22821614,  2.98540156]), camera_id=1, name='00000.png', xys=array([[475.42715454,   3.21835947],
       [428.53314209,   5.41732264],
       [428.53314209,   5.41732264],
       ...,
       [291.12200928,  92.76355743],
       [412.06417847, 319.75140381],
       [412.06417847, 319.75140381]]), 
       point3D_ids=array([-1, -1, 52838, 51638, -1, 49220,   
            ..., 
            51531, -1, 51681, 52214]))
~~~
### point3D.bin

~~~
def readColmapCameras(cam_extrinsics, cam_intrinsics, images_folder):
    cam_infos = []
    for idx, key in enumerate(cam_extrinsics):
        sys.stdout.write('\r')
        # the exact output you're looking for:
        sys.stdout.write("Reading camera {}/{}".format(idx+1, len(cam_extrinsics)))
        sys.stdout.flush()

        extr = cam_extrinsics[key]
        intr = cam_intrinsics[extr.camera_id]
        height = intr.height
        width = intr.width

        uid = intr.id
        R = np.transpose(qvec2rotmat(extr.qvec))
        T = np.array(extr.tvec)

        if intr.model=="SIMPLE_PINHOLE":
            focal_length_x = intr.params[0]
            FovY = focal2fov(focal_length_x, height)
            FovX = focal2fov(focal_length_x, width)
        elif intr.model=="PINHOLE":
            focal_length_x = intr.params[0]
            focal_length_y = intr.params[1]
            FovY = focal2fov(focal_length_y, height)
            FovX = focal2fov(focal_length_x, width)
        else:
            assert False, "Colmap camera model not handled: only undistorted datasets (PINHOLE or SIMPLE_PINHOLE cameras) supported!"

        image_path = os.path.join(images_folder, os.path.basename(extr.name))
        image_name = os.path.basename(image_path).split(".")[0]
        image = Image.open(image_path)

        cam_info = CameraInfo(uid=uid, R=R, T=T, FovY=FovY, FovX=FovX, image=image,
                              image_path=image_path, image_name=image_name, width=width, height=height)
        cam_infos.append(cam_info)
    sys.stdout.write('\n')
    return cam_infos
~~~

其中重要的有两点