---
title: LightLab
author: liliazhen669
date: 2025-05-10 16:00:00 +0800
categories: [Learning, RLearning]
tags: [paper] # TAG names should always be lowercas
render_with_liquid: false
math: true
---

# LightLab:Controlling Light Sources in Images with Diffusion Models

## 摘要


现存的方法要么依赖多视角的输入以在推理中执行反渲染，要么不能够在light change方面提供显式的控制。本文的方法在一个配对小摄影数据集上微调扩散模型，并辅以按比例合成的渲染图像，以实现更加逼真的重新照明。文本利用光传输的线性性质来合成图像对，描绘目标光源或环境照明的受控光变化。使用这些数据和适当的微调方案，本文训练了用于精确照明变化，并且能够明确控制光强度和颜色的模型。最后，本文还展示了提出的方法如何获得引人注目的光线编辑结果，并根据用户调研以证明效果超越了现有方法

## 主要贡献

## 方法

### 数据集构建

![fig-2](assets/img/lightlab/figure2.png)

**Photography capture.** 首先使用了几个先进的移动设备，收集了600组未经处理的照片对（photography pairs）。此外为了确保采集的照片是well-exposed的，在每个采集设备上设置了默认的自动曝光，以及使用了raw image的元信息（meta data）在post-capture中对照片进行校对。这样采集出来的数据集，提供了几何，材质表面以及复杂光现象（在合成数据集中，光现象：light phenomena 可能难以体现）的细节

Following先前的工作（A Dataset of Flash and Ambient Illumination Pairs from the Crowd. 2018等；），本文将 "off image"视为ambient illumination $i_{amb} := i_{off}$，以及从target light中提取illumination $i_{change}=i_{on}-i_{off}$。
由于采集噪声，post-capture calibration中的误差，或者在两张图片中的ambient illumination的轻微区别的存在，这个减法可能会出现负值。为了避免这种情况，做出以下的clip处理：$i_{change}=clip(i_{on}-i_{off}, 0)$。

**Synthetic rendering.** 为了补足训练用的数据集，本文使用了基于物理渲染的3D场景合成图像，合成数据的采集方法如下所示：首先从由3D艺术家使用Blender创作的20张合成室内场景开始。Rendering pipeline会随机地设置相机视角，虚拟光源及其相应参数，诸如光源强度，色温，光源区域尺寸，角度等（intensity，color temperature，area size，cone angle，etc）。然后通过随机采样合理的light fixture location以及将光源添加到场景当中来扩展合成数据集。进一步，还使用了不同strength的不同环境图以及随机设置背景光照。（其他具体内容参见附录）

本文分别地使用每一个light component $i_{amb}$ 和 $i_{change}$ 渲染合成图像，这两个组件 $i_{amb}$ 和 $i_{change}$ 会在下一节中进一步组合。图像是通过蒙特卡洛光线追踪渲染器，在线性RGB空间中创建的。通常情况下，当一条光路的采样概率特别低的时候，这会导致采样出无界的异常像素值。为此以应用了一个界$E_{max}$，设置为前 5×10−4 个百分位数的像素值，在 2000 次随机渲染的子集上计算

该数据集涵盖 16,000 个目标光源，相机视角，和环境照明，然后这些内容会在后处理过程中进行数据增强，后处理系数为 36，总计约 600K 张图像。尽管该数据集在场景几何以及材质中的分布密度相对较低（relatively low density in scene geometries and materials），在本文的实验部分中，依然展示了合成数据训练出来模型能够创建物理上合理且视图一致的光照（physically plausible and view-consistent lighting）。

### 基于图像的重光照（Image-based Relighting）
在该部分在，给定解耦的线性RGB图像 $i_{amb}$ 和 $i_{change}$，生成具有不同目标光源强度和颜色，以及环境照明的图像参数序列（parametric sequence）。

$$
\begin{equation}
\mathbf{i}_{\mathrm{relit}}\left(\alpha,\gamma,\mathbf{c}_{\mathrm{t}};\mathbf{i}_{\mathrm{amb}},\mathbf{i}_{\mathrm{change}}\right)=\alpha\mathbf{i}_{\mathrm{amb}}+\gamma\mathbf{i}_{\mathrm{change}}\mathbf{c}
\end{equation}
$$

### 色调映射策略（Tone-Mapping Strategy）

![fig-4](assets/img/lightlab/figure4.png)

由公式（1）生成的Relit图像序列需要进行色调映射以在基扩散模型的训练数据分布中对齐。一种方法是对每一个relit图像进行单独地色调映射以保证其是well-exposed的，但是作者发现这种方式会产生光照不一致的图像序列，感知到的光强度变化与物理变化不一致。例如，当目标光源在动态范围中占主导地位时，随着强度的增加，它看起来是恒定的，而环境光则变暗。（图4）

为解决这一个问题，作者使用了相同且固定的曝光来对图像序列进行色调映射。给定线性空间中的图像对：$i_{off}$ 和 $i_{on}$，作者启发式地（heuristically）,分别地为目标光源，环境光（ambient light）选择决定强度$\gamma_{d}$ 和 $\alpha_{d}$。[Burst photography for high dynamic range and low-light imaging on mobile cameras.] 中使用的合成曝光是根据 relit 图像 $i_{relit}(\alpha_{d},\gamma_{d},c_{t};i_{amb},i_{change})$ 计算的，并应用于所有不同的光源和环境光强度组合。

虽然使用固定曝光可以生成直观的光照强度变化序列，但单独用于训练重新光照模型时可能会出现问题。首先，在推理时，期望输入图像使用自动曝光进行捕捉，并单独进行色调映射。其次，希望允许用户决定模型输出的色调映射方式，从而控制在良好曝光输出和直观光照变化之间的平衡。因此，作者使用了两种策略对数据进行色调映射，并将所使用的策略作为输入条件提供给扩散模型。


### 使用扩散模型的光源控制

![fig-3](assets/img/lightlab/figure3.png)

**spatial conditions.**空间条件包括输入图像，由输入图像提取的深度图像，以及两张对于光源强度变化（light source intensity change）和光源颜色的空间分割掩码(即空间条件总计 **4** 张图像)。为了表示目标光源，本文使用一种由用户给定的一个bbox来指定的语义分割掩码（SAM 2: Segment Anything in Images and Videos）。该掩码会被使用两次以条件化建模光源强度和光源颜色。对于光源强度条件，掩码会和相对光强度变化标量（relative light intensity change scalar，对应于公式(1)中的 $\gamma$）相乘。而对于目标光源颜色条件，掩码会被扩展为3通道以及被缩放到要求的目标RGB颜色空间中（对应于公式（1）中的参数 $c$）。输入图像通过VAE被投影到隐空间，其他三张图像则会被缩放到隐空间的尺寸。紧接着，一个可学习的 $1 \times 1$ 卷积会被用来对齐空间条件张量的通道维度数量。空间条件输出的张量会和一个隐空间中的噪声张量进行通道维度上的相加。别的具体内容作者放到了附录里面。


**global condition.** 全局条件包括两个：取值为[-1, 1]的标量，ambient light change以及能够在推理过程中影响生成图像的曝光的色调映射策略二值化标量。全局控制会被将全局条件投影到和扩散模型的文本编码空间维度匹配的，可学习的MLP编码成傅里叶特征（图4）。被MLP投影后的结果会和扩散模型的文本嵌入在通道维度上进行相加，然后插入到文本到图像扩散模型的交叉注意力层中作为条件。
