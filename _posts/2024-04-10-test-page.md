---
title: UR5
date: 2024-05-2 15:37
category: robot
author: winka9587
tags: [robotArm]
summary: Summary of the article
---
## TODO

不再需要测试页面, 但是保留该页面, 用来暂时存储准备写但是还不值得单独创建一个post的内容

## 3dgs的缩放问题

起源于在使用点云初始化3dgs时, 试图寻找create_from_pcd函数中第二个参数的解释时, 发现了下面的[issue](https://github.com/graphdeco-inria/gaussian-splatting/issues/38)

其中[提到](https://github.com/graphdeco-inria/gaussian-splatting/issues/38#issuecomment-1638468622), 尺度问题对于缩放和位置可能是简单的, 但是对于旋转可能变换很大, 尤其是用来做pose estimation的时候.

*From my understanding you're right that both the scales and positions are easy to scale, however the real problem here is the rotations.*

*I bet you, that if you took EXACTLY the same scene and just rescaled it, you'd get VASTLY different 'rotation' results (whether that matters for the kind of* nerf-scenes we're optimizing is a different question), but I bet you at one end of the scale continuum they all stay at 'eye' rotation, and at the other end they all happy rotate around to wherever...

*Like I said, maybe it doesn't matter too much for making volume rendering look good, but for other apps where rotation is important (e.g. estimating camera poses) this matters ALOT...*

*About 1 year ago I did a lot of investigations into this with @leonidk and the best we came up with at the time was just to make sure to normalize your scene before optimizing (although maybe he has more opinions).*

所以会有什么问题？没能理解

spatial_lr_scale根据我的理解，是根据当前场景的尺寸来修改学习率的初值，也就是对初值进行缩放。而且根据[其他issue的反馈](https://github.com/graphdeco-inria/gaussian-splatting/issues/49)，学习率其实对于最终的渲染效果有很大的影响。有必要的话甚至需要手动去调整它。（因为对于3dgs的训练, 学习率动态调整是比较重要的一环）

关于这个参数值

在vanilla 3dgs的代码中:

<details>
<summary>Click to expand!</summary>

~~~
"""
    translate: np.array 均值点取反, 便于之后计算世界坐标系的均值化后的坐标
    radius: float 相机中心点到最远的相机中心点的距离 * 1.1
"""
def getNerfppNorm(cam_info):
    def get_center_and_diag(cam_centers):
        cam_centers = np.hstack(cam_centers)
        avg_cam_center = np.mean(cam_centers, axis=1, keepdims=True)
        center = avg_cam_center
        dist = np.linalg.norm(cam_centers - center, axis=0, keepdims=True)
        diagonal = np.max(dist)
        return center.flatten(), diagonal

    cam_centers = []

    for cam in cam_info:
        W2C = getWorld2View2(cam.R, cam.T)
        C2W = np.linalg.inv(W2C)
        cam_centers.append(C2W[:3, 3:4])

    center, diagonal = get_center_and_diag(cam_centers)
    radius = diagonal * 1.1

    translate = -center

    return {"translate": translate, "radius": radius}
~~~
</details>

该函数get_center_and_diag首先计算所有相机中心点的均值（avg_cam_center），然后计算每个相机中心点到这个均值中心点的距离（dist），最后取最大距离作为对角线长度（diagonal），最后取该值的1.1倍作为场景的半径。该结果最终被传入为spatial_lr_scale, 作为学习率的乘数。


cf3dgs在使用点云初始化3dgs时, 使用的是:

~~~
    radius = np.linalg.norm(input.points,axis=1).max()
~~~

计算的是点云中所有点到原点的最大距离，但根据注释来看, 作者也不确定这样是否正确。因为与vanilla 3dgs中使用相机的中心点来计算完全不同。（而且这一方法对于点云要求预先进行均值化）


## init single image

![](/assets/img/2024-07-16-14-27-13.png)

![](/assets/img/2024-07-16-14-27-29.png)

![](/assets/img/2024-07-16-14-27-57.png)

只要有pose或depth任意一个, 就会得到比现在更好的结果。