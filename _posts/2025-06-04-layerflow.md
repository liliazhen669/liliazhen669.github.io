---
title: LayerFlow
author: liliazhen669
date: 2025-06-04 18:00:00 +0800
categories: [Learning, Relighting]
tags: [paper] # TAG names should always be lowercas
render_with_liquid: false
math: true
---

# LayerFlow: A Unified Model for Layer-aware Video Generation

## Abstract

本文提出了 LayerFlow，一个能够感知图层的视频生成解决方案。根据每层的文本提示，LayerFlow 可以生成透明前景、清晰背景和混合场景的视频。它还支持多种变体，例如分解混合视频或为给定的前景生成背景，反之亦然。从文本到视频的扩散变换器开始，本文将不同层的视频组织为子片段，并利用层嵌入来区分每个片段和相应的图层提示。通过这种方式，在一个统一的框架中无缝地支持上述变体。由于缺乏高质量的图层训练视频，设计了一种多阶段训练策略，以适应具有高质量图层注释的静态图像。具体来说，首先使用低质量视频数据训练模型。然后，调整运动 LoRA，使模型与静态帧兼容。之后，利用混合了高质量分层图像和​​复制粘贴视频数据的 LoRA 内容进行训练。在推理过程中，去除了 LoRA 的运动部分，从而生成具有所需层次的流畅视频

## Introduction

本文工作的主要贡献如下：

LayerFlow 在生成质量和语义对齐方面展现出远超其他解决方案（例如仅基于视频进行训练或生成后再进行动画制作的解决方案）的出色能力。此外，通过去除指定视频片段中的噪声，可以对该片段进行条件化处理以生成剩余片段，从而在统一框架中实现图 1 中的多个衍生应用。例如，背景条件生成会在输入视频上绘制前景，反之亦然；而多层分解则会从给定视频中减去独立的视频层。LayerFlow 展现出作为分层视频创作基础解决方案的潜力，它能够通过多模态条件为更多奇特的应用赋能。

## Method

![fig-2](assets/img/layerflow/fig2.png)

LayerFlow的Pipeline如figure 2所示，分别地给定对于不同目标层级的三个文本输入，LayerFlow能够生成高保真的、以及与每层文本提示对齐的前景，alpha通道，背景以及融合的视频。在本部分的方法详述中，首先阐述整体框架，然后介绍构建在训练策略以及数据集贡献训练管线。

### Overall Framework

本文首先通过将所有层的子片段连接成一个整体以将基于 DiT 的 T2V 模型适配到层感知生成场景；然后通过在逐层文本嵌入上插入层嵌入，将每层的视觉内容与相应的文本提示对齐。
基于两个精心设计的 LoRA ，可以采用多阶段方案对模型进行微调，这将在 3.2 节关于联合图像-视频数据的说明中详细介绍，以合成高质量的视频。还可以基于这样一个统一的框架实现条件分层视频生成，以支持多种变体。

*Layer-wise video representation*。提出了一种简单有效的公式来表示视频中的不同层，将包括 alpha-matte 在内的各层的视觉嵌入连接成一个长序列。接下来的 3D 注意力机制将文本和视频关联起来，并在各层之间共享信息，从而增强层间一致性。需要注意的是，将前景分为 RGB 序列和 alpha 序列以表示透明度，因此可以将其组合为“RGBA 视频”以供进一步重组。

*Layer-wise text prompts*。为了使生成的视频片段分别指向相应的提示，建议对文本输入和编码嵌入进行文本修改，以赋予层感知能力。具体而言，在用 T5 编码的每个层的描述之前，以“索引号，层描述”的格式将索引号附加到提示中。编码后，可学习的层嵌入器将索引号投影到与文本嵌入大小相同的层嵌入，然后再添加到相应的文本嵌入中。所有上述修改以及位置嵌入，通过显式和隐式地建立文本和视觉嵌入对之间的对应关系，将每个层与其描述联系起来。

*Conditional layer generation*。还可以对该框架进行一些简单的修改，以支持各种条件层生成变体，包括前景/背景条件生成以及层分解。更具体地说，通过去除视觉嵌入的前景片段中的噪声，并将其从训练过程中的损失计算中分离出来，前景序列将作为剩余视频片段合成的条件，并且仅用于注意力共享，以建模层间关系。因此，该框架成为一个前景条件视频生成器。其他两个应用也进行了类似的修改，将在实验中演示所有这些变化。

### Training Pipeline

能够感知层的视频生成模型需要高质量的多层视频，这类视频往往难以获得或者构建。为了解决这个问题，本文提出了一个三阶段的训练策略，结合了静态图像和动态视频数据，利用了运动以及内容LoRA来解决数据稀缺这一问题，能够显著改进视频的内层连贯性，没血质量以及运动动态（inter-layer coherence，aesthetic quality, and motion dynamics）。

